模型评估与选择
==========================

### 经验误差与过拟合

- 经验误差：学习器在训练集上的误差称为经验误差
- 泛化误差：学习器在测试集上的误差称为泛化误差
- 过拟合：将样本的特征学习的太好，导致泛化能力性能下降的现象
- 欠拟合：样本的特性学习不够，泛化能力不行

### 评估方法

- 留出法：将给定数据集拆成互斥的两个集合，一个用于训练一个用于验证，一般训练集大小为原本集合的2/3~4/5
- 交叉验证法：将给定数据集拆成k个大小相似的互斥子集，每次使用k-1个训练，其余的验证。这样得到的k组训练/验证集合，最终返回k个验证结果的均值作为评估值。通常k取10
- 自助法：对给定数据集(大小为m)进行可重复采样m次，得到的集合作为训练集，其余的验证集。该方法引入了估计偏差，因此数据量足够时，一般不采用
- 通常测试集合上的判别效果用来评估实际使用的泛化能力，而把给定训练数据集合划分为训练集和验证集，基于验证集合上的性能进行模型选择和调参

### 性能度量
性能度量是衡量模型泛化能力的评价标准

#### 度量指标

- 错误率：分类错误的样本数占样本总数的比例
- 精度：分类正确的样本数占样本总数的比例
- 查准率(precision)：预测为类别A的样本数中，真正为A类型的样本数量比例
- 查全率(recall)：样本中类型为A的样本数中，真正被预测为A类型的样本数量比例
- 上述查全率与查准率是一对矛盾的度量，一般来说，查准率高时，查全率往往偏低，反之亦然。
- F1：基于查准率P和查全率R的调和平均，1/F1 = (1/P + 1/R)/2
- F_beta：基于查准率和查全率的加权调和平均 1/F_beta = (1/P + beta^2/R)/(1+beta^2)，其中beta>0，并且beta>1，则查全率的影响更大；beta<1，则查准率影响更大；beta=1，则退化成F1
- P-R图：纵坐标P横坐标R画的图，画出的曲线是同一分类器基于分类阈值的调节画出的曲线
- ROC曲线：纵坐标TPR(真正利率，查全率)横坐标FPR(假正利率)画的图，同样基于同一分类器调节分类阈值画出的曲线
- 泛化误差合理理解为偏差和方差和噪声只和
- 偏差度量了学习算法的期望预测与真实结果的偏离程度，刻画了学习算法本身的拟合能力
- 方差度量了同样大小的训练集的变动所导致的学习性能的变化，刻画了数据扰动所造成的的影响
- 噪声表达了当前任务上学习算法所能表达的期望泛化误差的下界，刻画了学习问题本身的难度
